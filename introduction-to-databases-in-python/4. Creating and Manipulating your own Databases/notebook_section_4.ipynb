{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Creating tables with SQLAlchemy\n",
    "Previously, you used the Table object to reflect a table from an existing database, but what if you wanted to create a new table? You'd still use the Table object; however, you'd need to replace the autoload and autoload_with parameters with Column objects.\n",
    "\n",
    "The Column object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints.\n",
    "\n",
    "When defining the table, recall how in the video Jason passed in 255 as the maximum length of a String by using Column('name', String(255)). Checking out the slides from the video may help: you can download them by clicking on 'Slides' next to the IPython Shell.\n",
    "\n",
    "After defining the table, you can create the table in the database by using the .create_all() method on metadata and supplying the engine as the only parameter. Go for it!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table('data', MetaData(bind=None), Column('name', String(length=255), table=<data>), Column('count', Integer(), table=<data>), Column('amount', Float(), table=<data>), Column('valid', Boolean(), table=<data>), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, create_engine, MetaData\n",
    "\n",
    "engine = create_engine('sqlite:///../datasets/mydatbase.sqlite')\n",
    "\n",
    "# Create a connection on engine\n",
    "connection = engine.connect()\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255)),\n",
    "             Column('count', Integer()),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean())\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print table details\n",
    "print(repr(data))\n"
   ]
  },
  {
   "source": [
    "# Constraints and data defaults\n",
    "You're now going to practice creating a table with some constraints! Often, you'll need to make sure that a column is unique, nullable, a positive value, or related to a column in another table. This is where constraints come in.\n",
    "\n",
    "As Jason showed you in the video, in addition to constraints, you can also set a default value for the column if no data is passed to it via the default keyword on the column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table('data', MetaData(bind=None), Column('name', String(length=255), table=<data>), Column('count', Integer(), table=<data>, default=ColumnDefault(1)), Column('amount', Float(), table=<data>), Column('valid', Boolean(), table=<data>, default=ColumnDefault(False)), schema=None)\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, create_engine, MetaData\n",
    "\n",
    "engine = create_engine('sqlite:///../datasets/mydatbase_1.sqlite')\n",
    "\n",
    "# Create a connection on engine\n",
    "connection = engine.connect()\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255), unique=True),\n",
    "             Column('count', Integer(), default=1),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean(), default=False)\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['data']))\n"
   ]
  },
  {
   "source": [
    "# Inserting a single row\n",
    "There are several ways to perform an insert with SQLAlchemy; however, we are going to focus on the one that follows the same pattern as the select statement.\n",
    "\n",
    "It uses an insert statement where you specify the table as an argument, and supply the data you wish to insert into the value via the .values() method as keyword arguments. For example, if my_table contains columns my_col_1 and my_col_2, then insert(my_table).values(my_col_1=5, my_col_2=\"Example\") will create a row in my_table with the value in my_col_1 equal to 5 and value in my_col_2 equal to \"Example\".\n",
    "\n",
    "Notice the difference in syntax: when appending a where statement to an existing statement, we include the name of the table as well as the name of the column, for example new_stmt = old_stmt.where(my_tbl.columns.my_col == 15). This is necessary because the existing statement might involve several tables.\n",
    "\n",
    "On the other hand, you can only insert a record into a single table, so you do not need to include the name of the table when using values() to insert, e.g. stmt = insert(my_table).values(my_col = 10).\n",
    "\n",
    "Here, the name of the table is data. You can run repr(data) in the console to examine the structure of the table."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n('Anna', 1, 1000.0, True)\n"
     ]
    }
   ],
   "source": [
    "# Import insert and select from sqlalchemy\n",
    "from sqlalchemy import select, insert\n",
    "\n",
    "# Build an insert statement to insert a record into the data table: insert_stmt\n",
    "insert_stmt = insert(data).values(name='Anna', count=1, amount=1000.00, valid=True)\n",
    "\n",
    "# Execute the insert statement via the connection: results\n",
    "results = connection.execute(insert_stmt)\n",
    "\n",
    "# Print result rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a select statement to validate the insert: select_stmt\n",
    "select_stmt = select([data]).where(data.columns.name == 'Anna')\n",
    "\n",
    "# Print the result of executing the query.\n",
    "print(connection.execute(select_stmt).first())\n"
   ]
  },
  {
   "source": [
    "# Inserting multiple records at once\n",
    "It's time to practice inserting multiple records at once!\n",
    "\n",
    "As Jason showed you in the video, when inserting multiple records at once, you do not use the .values() method. Instead, you'll want to first build a list of dictionaries that represents the data you want to insert, with keys being the names of the columns. in the .execute() method, you can pair this list of dictionaries with an insert statement, which will insert all the records in your list of dictionaries."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, create_engine, MetaData\n",
    "\n",
    "engine = create_engine('sqlite:///../datasets/mydatbase.sqlite')\n",
    "\n",
    "# Create a connection on engine\n",
    "connection = engine.connect()\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "# Build a list of dictionaries: values_list\n",
    "values_list = [\n",
    "    {'name': 'Anna', \n",
    "        'count': 1, \n",
    "        'amount': 1000.00, \n",
    "        'valid': True},\n",
    "    {'name': 'Taylor', \n",
    "        'count': 1, \n",
    "        'amount': 750.00, \n",
    "        'valid': False}\n",
    "]\n",
    "\n",
    "# Build an insert statement for the data table: stmt\n",
    "stmt = insert(data)\n",
    "\n",
    "# Execute stmt with the values_list: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n"
   ]
  },
  {
   "source": [
    "# Loading a CSV into a table\n",
    "You've done a great job so far at inserting data into tables! You're now going to learn how to load the contents of a CSV file into a table.\n",
    "\n",
    "One way to do that would be to read a CSV file line by line, create a dictionary from each line, and then use insert(), like you did in the previous exercise.\n",
    "\n",
    "But there is a faster way using pandas. You can read a CSV file into a DataFrame using the read_csv() function (this function should be familiar to you, but you can run help(pd.read_csv) in the console to refresh your memory!). Then, you can call the .to_sql() method on the DataFrame to load it into a SQL table in a database. The columns of the DataFrame should match the columns of the SQL table.\n",
    "\n",
    ".to_sql() has many parameters, but in this exercise we will use the following:\n",
    "\n",
    "- name is the name of the SQL table (as a string).\n",
    "- con is the connection to the database that you will use to upload the data.\n",
    "- if_exists specifies how to behave if the table already exists in the database; possible values are \"fail\", \"replace\", and \"append\".\n",
    "- index (True or False) specifies whether to write the DataFrame's index as a column.\n",
    "\n",
    "In this exercise, you will upload the data contained in the census.csv file into an existing table \"census\". The connection to the database has already been created for you."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read census.csv into a DataFrame : census_df\n",
    "census_df = pd.read_csv('../datasets/census.csv', header=None)\n",
    "\n",
    "# rename the columns of the census DataFrame\n",
    "census_df.columns = ['state', 'sex', 'age', 'pop2000', 'pop2008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the data from census_df to the \"census\" table via connection\n",
    "census_df.to_sql(name='census', con=connection, if_exists='append', index=False)"
   ]
  },
  {
   "source": [
    "# Updating individual records\n",
    "The update statement is very similar to an insert statement. For example, you can update all wages in the employees table as follows:\n",
    "\n",
    "```\n",
    "stmt = update(employees).values(wage=100.00)\n",
    "```\n",
    "\n",
    "The update statement also typically uses a where clause to help us determine what data to update. For example, to only update the record for the employee with ID 15, you would append the previous statement as follows:\n",
    "\n",
    "```\n",
    "stmt = stmt.where(employees.id == 15)\n",
    "```\n",
    "\n",
    "You'll be using the FIPS state code here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas.\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), name (Column), and fips_state (Column)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['employees']\n"
     ]
    }
   ],
   "source": [
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, create_engine, MetaData\n",
    "\n",
    "engine = create_engine('sqlite:///../datasets/employees.sqlite')\n",
    "\n",
    "# Create a connection on engine\n",
    "connection = engine.connect()\n",
    "\n",
    "# Print table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a select statement: select_stmt\n",
    "select_stmt = select([state_fact]).where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Execute select_stmt and fetch the results\n",
    "results = connection.execute(select_stmt).fetchall()\n",
    "\n",
    "# Print the results of executing the select_stmt\n",
    "print(results)\n",
    "\n",
    "# Print the FIPS code for the first row of the result\n",
    "print(results[0]['fips_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_stmt = select([state_fact]).where(state_fact.columns.name == 'New York')\n",
    "results = connection.execute(select_stmt).fetchall()\n",
    "print(results)\n",
    "print(results[0]['fips_state'])\n",
    "\n",
    "# Build a statement to update the fips_state to 36: update_stmt\n",
    "update_stmt = update(state_fact).values(fips_state = 36)\n",
    "\n",
    "# Append a where clause to limit it to records for New York state\n",
    "update_stmt = update_stmt.where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Execute the statement: update_results\n",
    "update_results = connection.execute(update_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_stmt = select([state_fact]).where(state_fact.columns.name == 'New York')\n",
    "results = connection.execute(select_stmt).fetchall()\n",
    "print(results)\n",
    "print(results[0]['fips_state'])\n",
    "\n",
    "update_stmt = update(state_fact).values(fips_state = 36)\n",
    "update_stmt = update_stmt.where(state_fact.columns.name == 'New York')\n",
    "update_results = connection.execute(update_stmt)\n",
    "\n",
    "# Execute select_stmt again and fetch the new results\n",
    "new_results = connection.execute(select_stmt).fetchall()\n",
    "\n",
    "# Print the new_results\n",
    "print(new_results)\n",
    "\n",
    "# Print the FIPS code for the first row of the new_results\n",
    "print(results[0]['fips_state'])\n"
   ]
  },
  {
   "source": [
    "# Updating multiple records\n",
    "As Jason discussed in the video, by using a where clause that selects more records, you can update multiple records at once. Unlike inserting, updating multiple records works exactly the same way as updating a single record (as long as you are updating them with the same value). It's time now to practice this!\n",
    "\n",
    "For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), notes (Column), and census_region_name (Column)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to update the notes to 'The Wild West': stmt\n",
    "stmt = update(state_fact).values(notes='The Wild West')\n",
    "\n",
    "# Append a where clause to match the West census region records: stmt_west\n",
    "stmt_west = stmt.where(state_fact.columns.census_region_name == 'West')\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt_west)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n"
   ]
  },
  {
   "source": [
    "# Correlated updates\n",
    "You can also update records with data from a select statement. This is called a correlated update. It works by defining a select statement that returns the value you want to update the record with and assigning that select statement as the value in update.\n",
    "\n",
    "You'll be using a flat_census in this exercise as the target of your correlated update. The flat_census table is a summarized copy of your census table, and contains, in particular, the fips_state columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select name from state_fact: fips_stmt\n",
    "fips_stmt = select([state_fact.columns.name])\n",
    "\n",
    "# Append a where clause to Match the fips_state to flat_census fips_code\n",
    "fips_stmt = fips_stmt.where(\n",
    "    state_fact.columns.fips_state == flat_census.columns.fips_code)\n",
    "\n",
    "# Build an update statement to set the name to fips_stmt: update_stmt\n",
    "update_stmt = update(flat_census).values(state_name=fips_stmt)\n",
    "\n",
    "# Execute update_stmt: results\n",
    "results = connection.execute(update_stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n"
   ]
  },
  {
   "source": [
    "# Deleting all the records from a table\n",
    "Often, you'll need to empty a table of all of its records so you can reload the data. You can do this with a delete statement with just the table as an argument. For example, in the video, Jason deleted the table extra_employees by executing as follows:\n",
    "\n",
    "```\n",
    "delete_stmt = delete(extra_employees)\n",
    "result_proxy = connection.execute(delete_stmt)\n",
    "```\n",
    "\n",
    "Do be careful, though, as deleting cannot be undone!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delete, select\n",
    "from sqlalchemy import delete, select\n",
    "\n",
    "# Build a statement to empty the census table: stmt\n",
    "delete_stmt = delete(census)\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(delete_stmt)\n",
    "\n",
    "# Print affected rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a statement to select all records from the census table : select_stmt\n",
    "select_stmt = select([census])\n",
    "\n",
    "# Print the results of executing the statement to verify there are no rows\n",
    "print(connection.execute(select_stmt).fetchall())\n"
   ]
  },
  {
   "source": [
    "# Deleting specific records\n",
    "By using a where() clause, you can target the delete statement to remove only certain records. For example, Jason deleted all rows from the employees table that had id 3 with the following delete statement:\n",
    "\n",
    "```\n",
    "delete(employees).where(employees.columns.id == 3) \n",
    "```\n",
    "\n",
    "Here you'll delete ALL rows which have 'M' in the sex column and 36 in the age column. We have included code at the start which computes the total number of these rows. It is important to make sure that this is the number of rows that you actually delete."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to count records using the sex column for Men ('M') age 36: count_stmt\n",
    "count_stmt = select([func.count(census.columns.sex)]).where(\n",
    "    and_(census.columns.sex == 'M',\n",
    "         census.columns.age == 36)\n",
    ")\n",
    "\n",
    "# Execute the select statement and use the scalar() fetch method to save the record count\n",
    "to_delete = connection.execute(count_stmt).scalar()\n",
    "\n",
    "# Build a statement to delete records from the census table: delete_stmt\n",
    "delete_stmt = delete(census)\n",
    "\n",
    "# Append a where clause to target Men ('M') age 36: delete_stmt\n",
    "delete_stmt = delete_stmt.where(\n",
    "    and_(census.columns.sex == 'M',\n",
    "         census.columns.age == 36)\n",
    ")\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(delete_stmt)\n",
    "\n",
    "# Print affected rowcount and to_delete record count, make sure they match\n",
    "print(results.rowcount, to_delete)\n"
   ]
  },
  {
   "source": [
    "# Deleting a table completely\n",
    "You're now going to practice dropping individual tables from a database with the .drop() method, as well as all tables in a database with the .drop_all() method!\n",
    "\n",
    "As Spider-Man's Uncle Ben (as well as Jason, in the video!) said: With great power, comes great responsibility. Do be careful when deleting tables, as it's not simple or fast to restore large databases! Remember, you can check to see if a table exists on an engine with the .exists(engine) method.\n",
    "\n",
    "This is the final exercise in this chapter: After this, you'll be ready to apply everything you've learned to a case study in the final chapter of this course!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the state_fact tables\n",
    "state_fact.drop(engine)\n",
    "\n",
    "# Check to see if state_fact exists\n",
    "print(state_fact.exists(engine))\n",
    "\n",
    "# Drop all tables\n",
    "metadata.drop_all(engine)\n",
    "\n",
    "# Check to see if census exists\n",
    "print(census.exists(engine))\n"
   ]
  }
 ]
}